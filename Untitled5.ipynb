{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "mount_file_id": "1szHXahP1Hcx4Zj45rJrxLclcmr8H0j9H",
      "authorship_tag": "ABX9TyPERxTQGlQ0das/GAYw6Mmu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Badaralam/trafficeflow_RNN/blob/master/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0-2qj1Zyqe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wukypTH50obe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from csv import reader\n",
        "\n",
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "\tfile = open(filename, \"r\")\n",
        "\tlines = reader(file)\n",
        "\tdataset = list(lines)\n",
        "\treturn dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSkjp2sezJAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "test_data = pd.read_csv (r'/content/drive/My Drive/dataPEMS/dataPEMS/PEMS_test.csv')  \n",
        " #read the csv file (put 'r' before the path string to address any special characters in the path, such as '\\'). Don't forget to put the file name at the end of the path + \".csv\"\n",
        "\n",
        "# Load dataset\n",
        "filename = '/content/drive/My Drive/dataPEMS/dataPEMS/randperm.csv'\n",
        "randperm = load_csv(filename)\n",
        "filename2=\"/content/drive/My Drive/dataPEMS/dataPEMS/PEMS_testlabels.csv\"\n",
        "test_dataset = load_csv(filename2)\n",
        "filename3='/content/drive/My Drive/dataPEMS/dataPEMS/PEMS_trainlabels.csv'\n",
        "train_dataset=load_csv(filename3)\n",
        "filename4='/content/drive/My Drive/dataPEMS/dataPEMS/stations_list.csv'\n",
        "stations_list=load_csv(filename4)\n",
        "#filename5='/content/drive/My Drive/dataPEMS/dataPEMS/PEMS_test.csv'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-TvPoQKkoV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load CSV using Pandas\n",
        "import pandas\n",
        "filename = '/content/drive/My Drive/dataPEMS/dataPEMS/PEMS_test.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "data = pandas.read_csv(filename, names=names)\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4tqAuiBIwkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "train_dataset=pandas.DataFrame(data=train_dataset)\n",
        "print(\"train data\",train_dataset.boxplot)\n",
        "test_dataset=pandas.DataFrame(data=test_dataset)\n",
        "print('test_data',test_dataset.boxplot)\n",
        "\n",
        "train_dataset=train_dataset.to_numpy()\n",
        "train_dataset.dtype\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQLtLpjwGZHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nfXof52G_c6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "STEP 3: CREATE MODEL CLASS\n",
        "'''\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super(RNNModel, self).__init__()\n",
        "        # Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # Number of hidden layers\n",
        "        self.layer_dim = layer_dim\n",
        "        \n",
        "        # Building your RNN\n",
        "        # batch_first=True causes input/output tensors to be of shape\n",
        "        # (batch_dim, seq_dim, feature_dim)\n",
        "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='tanh')\n",
        "        \n",
        "        # Readout layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
        "            \n",
        "        # One time step\n",
        "        out, hn = self.rnn(x, h0)\n",
        "        \n",
        "        # Index hidden state of last time step\n",
        "        # out.size() --> 100, 28, 100\n",
        "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
        "        out = self.fc(out[:, -1, :]) \n",
        "        # out.size() --> 100, 10\n",
        "        return out\n",
        "\n",
        "'''\n",
        "STEP 4: INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "input_dim = 1\n",
        "hidden_dim = 100\n",
        "layer_dim = 2  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER\n",
        "output_dim = 1\n",
        "\n",
        "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
        "print(model)\n",
        "\n",
        "#######################\n",
        "\n",
        "''''\n",
        "STEP 5: INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "'''\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "'''\n",
        "STEP 7: TRAIN THE MODEL\n",
        "'''\n",
        "\n",
        "# Number of steps to unroll\n",
        "seq_dim = 28  \n",
        "\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i,  labels in enumerate(train_dataset):\n",
        "        images = train_loader\n",
        "        labels = test_loader\n",
        "            \n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass to get output/logits\n",
        "        # outputs.size() --> 100, 10\n",
        "        outputs = model(images)\n",
        "        \n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "        \n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        iter += 1\n",
        "        \n",
        "        if iter % 500 == 0:\n",
        "                  \n",
        "            correct = 0\n",
        "            total = 0\n",
        "        \n",
        "            for images, labels in test_loader:\n",
        "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
        "                \n",
        "               \n",
        "                outputs = model(images)\n",
        "                \n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                \n",
        "              \n",
        "                total += labels.size(0)\n",
        "                \n",
        "                correct += (predicted == labels).sum()\n",
        "            \n",
        "            accuracy = 100 * correct / total\n",
        "            \n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data[0], accuracy))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnUjXyWUWZr-",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}